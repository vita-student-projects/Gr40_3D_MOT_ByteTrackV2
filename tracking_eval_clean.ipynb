{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the detections and ground truth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notbeook we will display the detections made by the custom detectors (MEGVII/transfusion) and the ground thruth found in nuscenes. We won't display the images, rather a BEV appreoach with different other metrics (IoU or distance on the ground plane)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ByteTrack\n",
    "import warnings\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from nuscenes.eval.tracking.data_classes import  TrackingConfig\n",
    "from nuscenes.eval.tracking.evaluate import TrackingEval\n",
    "import json\n",
    "import os\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Nuscenes object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n"
     ]
    }
   ],
   "source": [
    "# no need to run on v1.0-test because there are no annotations\n",
    "nusc = NuScenes(version='v1.0-trainval', dataroot=ByteTrack.TRAINVAL_PATH, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup params for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"results/tracking_eval_bevformer/\" # precise it only if you want to evaluate multiple tracking predictions\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) #due to warnings in pandas that are not relevant\n",
    "result_path = \"ByteTrack.json\" # path to the tracking result file\n",
    "eval_set = \"val\" # can be \"train\" \"val\" \"test\" is useless since we cannot evaluate on test set\n",
    "output_dir = \"eval_results_bytetrack_kalman_var\" # directory to save the evaluation results\n",
    "config_file = \"config/tracking_nips_2019.json\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate all the tracking json files in the deisgnated folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filenames in os.listdir(PATH): # Ã  utiliser une fois qu'on aura plusieurs fichiers pour faire nos plots\n",
    "    print(str(PATH+filenames))\n",
    "    trackEvalutation = TrackingEval(nusc_dataroot=TRAINVAL_PATH, nusc_version='v1.0-trainval', result_path=str(PATH+filenames), eval_set=eval_set, config=TrackingConfig(**json.load(open(config_file))), output_dir=output_dir+filenames[:-5], verbose=True)\n",
    "    trackEvalutation.main()    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate only one tracking json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 46.938 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 13.4 seconds.\n",
      "======\n",
      "Initializing nuScenes tracking evaluation\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trackEvalutation \u001b[39m=\u001b[39m TrackingEval(nusc_dataroot\u001b[39m=\u001b[39;49mByteTrack\u001b[39m.\u001b[39;49mTRAINVAL_PATH, nusc_version\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mv1.0-trainval\u001b[39;49m\u001b[39m'\u001b[39;49m, result_path\u001b[39m=\u001b[39;49mresult_path, eval_set\u001b[39m=\u001b[39;49meval_set, config\u001b[39m=\u001b[39;49mTrackingConfig(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mjson\u001b[39m.\u001b[39;49mload(\u001b[39mopen\u001b[39;49m(config_file))), output_dir\u001b[39m=\u001b[39;49moutput_dir, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      2\u001b[0m trackEvalutation\u001b[39m.\u001b[39mmain()\n",
      "File \u001b[1;32mc:\\Users\\eliot\\anaconda3\\envs\\semproj\\lib\\site-packages\\nuscenes\\eval\\tracking\\evaluate.py:83\u001b[0m, in \u001b[0;36mTrackingEval.__init__\u001b[1;34m(self, config, result_path, eval_set, output_dir, nusc_version, nusc_dataroot, verbose, render_classes)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n\u001b[0;32m     82\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mInitializing nuScenes tracking evaluation\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 83\u001b[0m pred_boxes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta \u001b[39m=\u001b[39m load_prediction(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresult_path, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcfg\u001b[39m.\u001b[39;49mmax_boxes_per_sample, TrackingBox,\n\u001b[0;32m     84\u001b[0m                                         verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[0;32m     85\u001b[0m gt_boxes \u001b[39m=\u001b[39m load_gt(nusc, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_set, TrackingBox, verbose\u001b[39m=\u001b[39mverbose)\n\u001b[0;32m     87\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mset\u001b[39m(pred_boxes\u001b[39m.\u001b[39msample_tokens) \u001b[39m==\u001b[39m \u001b[39mset\u001b[39m(gt_boxes\u001b[39m.\u001b[39msample_tokens), \\\n\u001b[0;32m     88\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mSamples in split don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt match samples in predicted tracks.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\eliot\\anaconda3\\envs\\semproj\\lib\\site-packages\\nuscenes\\eval\\common\\loaders.py:39\u001b[0m, in \u001b[0;36mload_prediction\u001b[1;34m(result_path, max_boxes_per_sample, box_cls, verbose)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m data, \u001b[39m'\u001b[39m\u001b[39mError: No field `results` in result file. Please note that the result format changed.\u001b[39m\u001b[39m'\u001b[39m \\\n\u001b[0;32m     36\u001b[0m                           \u001b[39m'\u001b[39m\u001b[39mSee https://www.nuscenes.org/object-detection for more information.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     38\u001b[0m \u001b[39m# Deserialize results and get meta data.\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m all_results \u001b[39m=\u001b[39m EvalBoxes\u001b[39m.\u001b[39;49mdeserialize(data[\u001b[39m'\u001b[39;49m\u001b[39mresults\u001b[39;49m\u001b[39m'\u001b[39;49m], box_cls)\n\u001b[0;32m     40\u001b[0m meta \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mmeta\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     41\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n",
      "File \u001b[1;32mc:\\Users\\eliot\\anaconda3\\envs\\semproj\\lib\\site-packages\\nuscenes\\eval\\common\\data_classes.py:132\u001b[0m, in \u001b[0;36mEvalBoxes.deserialize\u001b[1;34m(cls, content, box_cls)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[39mInitialize from serialized content.\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[39m:param content: A dictionary with the serialized content of the box.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39m:param box_cls: The class of the boxes, DetectionBox or TrackingBox.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m eb \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m()\n\u001b[1;32m--> 132\u001b[0m \u001b[39mfor\u001b[39;00m sample_token, boxes \u001b[39min\u001b[39;00m content\u001b[39m.\u001b[39;49mitems():\n\u001b[0;32m    133\u001b[0m     eb\u001b[39m.\u001b[39madd_boxes(sample_token, [box_cls\u001b[39m.\u001b[39mdeserialize(box) \u001b[39mfor\u001b[39;00m box \u001b[39min\u001b[39;00m boxes])\n\u001b[0;32m    134\u001b[0m \u001b[39mreturn\u001b[39;00m eb\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "trackEvalutation = TrackingEval(nusc_dataroot=TRAINVAL_PATH, nusc_version='v1.0-trainval', result_path=result_path, eval_set=eval_set, config=TrackingConfig(**json.load(open(config_file))), output_dir=output_dir, verbose=True)\n",
    "trackEvalutation.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a1eca162d8244ec663334057c1610a3bae01391a28d85af84dac413dee83203"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
